V. CONCLUSION
In this paper, we present comprehensive gait research for KAM estimation during walking, including the hardware setup, experimental procedure, data processing, deep-learning model designing, and experiment analysis. The proposed model used LSTM Feature Extraction encoders to extract temporal features. The IMU and EMG features are fused by the proposed attention-dependence module. The KAM result is precisely estimated using an intricately designed decoder based on kinematic modeling. Experiments show that the explainable kinematic attention dependence fusion of IMU and EMG features achieves the highest accuracy of the KAM estimation. Our work significantly contributes to the advancement of wearable devices and deep-learning technologies within personalized medicine and wearable informatics, with a pronounced emphasis on early detection, and has positive significance for future treatment. The primary limitations of the work include the lack of data from other dimensions of gait data and patients with musculoskeletal disorders. Potential applications include regular monitoring of KAM in daily life after future long-term clinical validation for patients with musculoskeletal disorders.

V. CONCLUSION
Our MDSA-UNet model demonstrates strong potential for medical image segmentation, particularly in assisting radiologists and clinicians with efficient and accurate diagnosis. By maintaining a balance between computational efficiency and segmentation accuracy, it can be deployed in real-time decision support systems, benefiting applications in oncology, cardiology, and other medical domains. Additionally, its ability to capture fine-grained structural details can enhance disease detection and monitoring, ultimately contributing to improved patient outcomes. Future research will focus on enhancing realtime adaptability, integrating multi-modal data, and leveraging advanced learning techniques to further improve segmentation performance and clinical applicability.

V. CONCLUSION
This work demonstrated that tracing medical fluid samples with deep learning object detection is feasible. Our investigations were focused on whole blood plasma portion tracing. The experimental dataset contained 976 unique samples stored 17 different types of sample containers from 11 manufacturers. One of the main challenges was due to variability of the available clearance window size for viewing inside the sample containers. We developed and proved the efficacy of a new input representation method called vertical image stitching. Based on the proposed vertical image stitching we introduced a new data augmentation technique named random stitch permutation and we also changed the 2D bounding box computation to 1D points localization for the liquid levels tracing. We trained and fine-tuned YoloV4-tiny with the proposed input representation and augmentation techniques and achieved an average precision of 98.09% at intersection over union threshold of 0.90, with an average intersection over union of 95.18%. Our method proves high localization precision and robustness across container types and clearance window sizes. The proposed model significantly outperforms the original YoloV4-tiny and YoloV7-tiny on the experimental dataset. Future work could be done for improving the localization precision of the model by switching to a newer state-of-the-art architectures for the object detector. Although weâ€™ve generated and used a dataset of almost 1,000 unique samples, more samples could be added to the dataset to ensure sufficient coverage for all possible variations of real blood (e.g. presence of interferences such as high amounts of hemoglobin, lipids, white cells etc.)