"""
åŒæ¨¡æ€YOLOæ¨¡å‹è¯„ä¼°è„šæœ¬V3 - ä¼˜åŒ–ç‰ˆ
- æŒ‰ç±»åˆ«ç‹¬ç«‹è¯„ä¼°ï¼ˆclass 0, 1, 2åˆ†å¼€ç»Ÿè®¡ï¼‰
- ä¸»è¦æŒ‡æ ‡ï¼šMask mAP@0.5, mAP@0.5:0.95, Precision, Recall, F1
- è¾…åŠ©æŒ‡æ ‡ï¼šDetection Rate, IoU, Surface Diff
"""

import torch
import sys
import os
import json
import numpy as np
import cv2
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from ultralytics import YOLO
from dual_dataset.d_dataset_config import DatasetConfig
from ultralytics.utils.metrics import ap_per_class


class mAPCalculator:
    """åŸºäºUltralyticsçš„Mask mAPè®¡ç®—å™¨ï¼ˆç§»é™¤Box mAPï¼‰"""

    def __init__(self, class_config):
        self.class_config = class_config
        self.iou_thresholds = np.linspace(0.5, 0.95, 10)

        # ç´¯ç§¯æ•°æ®ï¼ˆè·¨æ‰€æœ‰æµ‹è¯•å›¾åƒï¼‰
        self.all_tp_mask = []
        self.all_conf = []
        self.all_pred_cls = []
        self.all_target_cls = []

    def collect(self, tp_mask, conf, pred_cls, target_cls):
        """æ”¶é›†å•å¼ å›¾åƒçš„æ£€æµ‹æ•°æ®"""
        if len(tp_mask) > 0:
            self.all_tp_mask.append(tp_mask)
            self.all_conf.append(conf)
            self.all_pred_cls.append(pred_cls)

        if len(target_cls) > 0:
            self.all_target_cls.append(target_cls)

    def compute(self):
        """è®¡ç®—Mask mAPå’Œç›¸å…³æŒ‡æ ‡"""
        if not self.all_tp_mask:
            return None

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        tp_mask = np.vstack(self.all_tp_mask)
        conf = np.concatenate(self.all_conf)
        pred_cls = np.concatenate(self.all_pred_cls)
        target_cls = np.concatenate(self.all_target_cls)

        # è®¡ç®—Mask AP
        results_mask = ap_per_class(
            tp_mask, conf, pred_cls, target_cls,
            plot=False, save_dir=Path(), names={}
        )

        # è§£æç»“æœï¼š(tp, fp, p, r, f1, ap, unique_classes, ...)
        _, _, p_mask, r_mask, f1_mask, ap_mask, unique_classes, *_ = results_mask

        # æŒ‰ç±»åˆ«ç»„ç»‡ç»“æœ
        per_class_results = {}
        for i, class_id in enumerate(unique_classes):
            class_id = int(class_id)
            per_class_results[class_id] = {
                'mask_ap50': float(ap_mask[i, 0]) if len(ap_mask.shape) > 1 else 0.0,
                'mask_ap75': float(ap_mask[i, 5]) if len(ap_mask.shape) > 1 else 0.0,
                'mask_ap50_95': float(ap_mask[i].mean()) if len(ap_mask.shape) > 1 else 0.0,
                'precision': float(p_mask[i]) if len(p_mask) > 0 else 0.0,
                'recall': float(r_mask[i]) if len(r_mask) > 0 else 0.0,
                'f1_score': float(f1_mask[i]) if len(f1_mask) > 0 else 0.0
            }

        return per_class_results


class DualYOLOEvaluatorV3:
    def __init__(self, fusion_name, train_mode, conf_threshold=0.5):
        self.fusion_name = fusion_name
        self.conf_threshold = conf_threshold
        self.project_root = Path(__file__).parent.parent
        self.model = None
        self.train_mode = train_mode
        self.config = DatasetConfig()

        # ç±»åˆ«é…ç½®
        self.class_config = {
            0: {'name': 'serum', 'display_name': 'è¡€æ¸…å±‚'},
            1: {'name': 'buffy_coat', 'display_name': 'ç™½è†œå±‚'},
            2: {'name': 'plasma', 'display_name': 'è¡€æµ†å±‚'}
        }

        # ç»“æœä¿å­˜è·¯å¾„
        self.results_dir = self.project_root / 'dual_yolo' / 'evaluation_results_v3' / f'conf_{conf_threshold}' / fusion_name
        self.vis_dir = self.results_dir / 'sample_visualizations'
        os.makedirs(self.results_dir, exist_ok=True)
        os.makedirs(self.vis_dir, exist_ok=True)

        # æŒ‰ç±»åˆ«ç‹¬ç«‹å­˜å‚¨metrics
        self.per_class_metrics = {
            0: self._create_class_metric_structure(),
            1: self._create_class_metric_structure(),
            2: self._create_class_metric_structure()
        }

        # mAPè®¡ç®—å™¨
        self.map_calculator = mAPCalculator(class_config=self.class_config)

        # æ€»ä½“ç»Ÿè®¡
        self.total_images = 0
        self.overall_success_count = 0  # æ‰€æœ‰ç±»åˆ«éƒ½æ­£ç¡®æ£€æµ‹çš„å›¾åƒæ•°

    def _create_class_metric_structure(self):
        """åˆ›å»ºå•ä¸ªç±»åˆ«çš„metricç»“æ„"""
        return {
            'medical_metrics': {
                'total_samples': 0,
                'detected_samples': 0,
                'detection_rate': 0.0,
                'iou_scores': [],
                'upper_surface_diffs': [],
                'lower_surface_diffs': []
            },
            'raw_data': {
                'iou_scores': [],
                'upper_surface_diffs': [],
                'lower_surface_diffs': []
            }
        }

    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if self.fusion_name:
            # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šcrossattn-30epochä½¿ç”¨crossattnçš„æ¨¡å‹æ¶æ„
            if self.fusion_name == 'crossattn-30epoch':
                model_yaml = self.project_root / 'dual_yolo' / 'models' / f'yolo11x-dseg-crossattn.yaml'
            else:
                model_yaml = self.project_root / 'dual_yolo' / 'models' / f'yolo11x-dseg-{self.fusion_name}.yaml'

            model_pt = self.project_root / 'dual_yolo' / 'runs' / 'segment' / f'dual_modal_{self.train_mode}_{self.fusion_name}' / 'weights' / 'best.pt'

        try:
            self.model = YOLO(model_yaml).load(model_pt)
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {self.fusion_name}")
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def parse_yolo_label(self, label_file):
        """è§£æYOLOæ ‡ç­¾æ–‡ä»¶"""
        if not os.path.exists(label_file):
            return {}

        class_masks = {}
        with open(label_file, 'r') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue

                parts = line.split()
                class_id = int(parts[0])
                coords = list(map(float, parts[1:]))

                # è½¬æ¢å½’ä¸€åŒ–åæ ‡åˆ°åƒç´ åæ ‡
                points = []
                for i in range(0, len(coords), 2):
                    x = coords[i] * 1504
                    y = coords[i + 1] * 1504
                    points.append([x, y])

                class_masks[class_id] = np.array(points, dtype=np.float32)

        return class_masks

    def calculate_iou(self, pred_points, true_points):
        """è®¡ç®—Mask IoU"""
        # åˆ›å»ºé¢„æµ‹mask
        pred_mask = np.zeros((1504, 1504), dtype=np.uint8)
        cv2.fillPoly(pred_mask, [pred_points.astype(np.int32)], 255)

        # åˆ›å»ºçœŸå®mask
        true_mask = np.zeros((1504, 1504), dtype=np.uint8)
        cv2.fillPoly(true_mask, [true_points.astype(np.int32)], 255)

        # è®¡ç®—IoU
        intersection = np.logical_and(pred_mask > 0, true_mask > 0).sum()
        union = np.logical_or(pred_mask > 0, true_mask > 0).sum()

        return intersection / union if union > 0 else 0.0


    def calculate_surface_diff(self, pred_points, true_points, rotation_angle):
        """è®¡ç®—ä¸Šä¸‹è¡¨é¢å·®å¼‚"""
        # å°†é¢„æµ‹ç‚¹å’ŒçœŸå®ç‚¹éƒ½åå‘æ—‹è½¬åˆ°åŸå§‹åæ ‡ç³»è¿›è¡Œæ¯”è¾ƒ
        pred_original = self.apply_rotation(pred_points, -rotation_angle)
        true_original = self.apply_rotation(true_points, -rotation_angle)

        # è·å–yåæ ‡å¹¶æ’åº
        pred_y = np.sort(pred_original[:, 1])
        true_y = np.sort(true_original[:, 1])

        # è®¡ç®—ä¸Šä¸‹è¡¨é¢ï¼ˆå–å‰3ä¸ªå’Œå3ä¸ªç‚¹çš„å‡å€¼ï¼‰
        pred_upper = np.mean(pred_y[:3])
        pred_lower = np.mean(pred_y[-3:])
        true_upper = np.mean(true_y[:3])
        true_lower = np.mean(true_y[-3:])

        upper_diff = abs(pred_upper - true_upper)
        lower_diff = abs(pred_lower - true_lower)

        return upper_diff, lower_diff

    def apply_rotation(self, points, angle, img_size=(1504, 1504)):
        """åº”ç”¨æ—‹è½¬å˜æ¢"""
        if angle == 0:
            return points

        center = (img_size[0] // 2, img_size[1] // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)

        # è½¬æ¢ä¸ºé½æ¬¡åæ ‡
        points_array = np.array(points, dtype=np.float32)
        ones = np.ones((points_array.shape[0], 1), dtype=np.float32)
        homogeneous_points = np.hstack([points_array, ones])

        # åº”ç”¨æ—‹è½¬
        rotated_points = rotation_matrix.dot(homogeneous_points.T).T

        # è£å‰ªåˆ°å›¾åƒè¾¹ç•Œ
        rotated_points[:, 0] = np.clip(rotated_points[:, 0], 0, img_size[0] - 1)
        rotated_points[:, 1] = np.clip(rotated_points[:, 1], 0, img_size[1] - 1)

        return rotated_points

    def visualize_sample(self, npy_file, dual_tensor, detected_classes, true_masks, results, rotation_angle, is_successful_detection=True):
        """å¯è§†åŒ–å•ä¸ªæ ·æœ¬"""
        # å‡†å¤‡å¯è§†åŒ–å›¾åƒï¼ˆä½¿ç”¨è“å…‰é€šé“ï¼‰
        blue_channels = dual_tensor[:3, :, :][[2, 1, 0], :, :]  # BGRé€šé“é¡ºåº
        blue_image = blue_channels.transpose(1, 2, 0)
        vis_image = np.clip(blue_image * 255 if blue_image.max() <= 1.0 else blue_image, 0, 255).astype(np.uint8)
        vis_image = np.ascontiguousarray(vis_image)

        # é¢„æµ‹ç‚¹é¢œè‰²æ–¹æ¡ˆ (BGRæ ¼å¼)
        pred_colors = {0: (0, 255, 255), 1: (0, 255, 0), 2: (255, 0, 0)}  # é»„ã€ç»¿ã€è“

        # ç»˜åˆ¶çœŸå®æ ‡æ³¨ç‚¹ (çº¢è‰²åœ†ç‚¹)
        for class_id, true_points in true_masks.items():
            for point in true_points:
                cv2.circle(vis_image, tuple(map(int, point)), 5, (0, 0, 255), -1)

        # ç»˜åˆ¶é¢„æµ‹ç»“æœ
        for class_id, detection_indices in detected_classes.items():
            if class_id in pred_colors:
                pred_color = pred_colors[class_id]
                for detection_idx in detection_indices:
                    # æå–é¢„æµ‹ç‚¹
                    pred_points = results[0][detection_idx].masks.xyn[0].copy()
                    pred_points[:, 0] *= 1504
                    pred_points[:, 1] *= 1504

                    # ç»˜åˆ¶é¢„æµ‹çº¿è¿æ¥ (ç™½è‰²ç»†çº¿)
                    pred_line = np.array(pred_points, dtype=np.int32).reshape((-1, 1, 2))
                    cv2.polylines(vis_image, [pred_line], True, (255, 255, 255), 1, lineType=cv2.LINE_AA)

                    # ç»˜åˆ¶é¢„æµ‹ç‚¹åå­—
                    for point in pred_points:
                        x, y = int(point[0]), int(point[1])
                        cv2.line(vis_image, (x-3, y), (x+3, y), pred_color, 2)
                        cv2.line(vis_image, (x, y-3), (x, y+3), pred_color, 2)

        # ä¿å­˜å¯è§†åŒ–å›¾åƒ
        base_filename = npy_file.replace('.npy', '')
        suffix = '_eval.jpg' if is_successful_detection else '_lack_detection.jpg'
        save_path = self.vis_dir / f'{base_filename}{suffix}'

        cv2.imwrite(str(save_path), vis_image)

    def evaluate_single_image(self, npy_file, test_images_dir, test_labels_dir):
        """è¯„ä¼°å•å¼ å›¾åƒ"""
        try:
            # åŠ è½½å›¾åƒæ•°æ®
            dual_tensor = np.load(test_images_dir / npy_file)
            if dual_tensor.shape[-1] == 6:
                dual_tensor = dual_tensor.transpose(2, 0, 1)

            # å‡†å¤‡æ¨¡å‹è¾“å…¥
            model_tensor = dual_tensor / 255.0 if dual_tensor.max() > 1.0 else dual_tensor
            model_input = torch.from_numpy(model_tensor).unsqueeze(0).float()

            # è·å–æ—‹è½¬è§’åº¦
            suffix = npy_file.split('_')[-1].replace('.npy', '')
            rotation_angle = self.config.strategies.get(suffix, {}).get('rotation', 0)

            # åŠ è½½çœŸå®æ ‡ç­¾
            label_file = test_labels_dir / npy_file.replace('.npy', '.txt')
            true_masks = self.parse_yolo_label(label_file)

            if not true_masks:
                return False

            # æ¨¡å‹æ¨ç†
            device = "cuda:3" if torch.cuda.is_available() else "cpu"
            results = self.model(model_input, imgsz=1504, device=device, verbose=False, conf=self.conf_threshold)

            # æ£€æµ‹ç»“æœåˆ†ç»„
            detected_classes = {}
            if hasattr(results[0], 'boxes') and results[0].boxes is not None and len(results[0].boxes) > 0:
                all_classes = results[0].boxes.cls.cpu().numpy()
                for i, cls_id in enumerate(all_classes):
                    cls_id = int(cls_id)
                    if cls_id not in detected_classes:
                        detected_classes[cls_id] = []
                    detected_classes[cls_id].append(i)

            # æŒ‰ç±»åˆ«ç‹¬ç«‹è¯„ä¼°ï¼ˆåŒ»å­¦æŒ‡æ ‡ï¼‰
            class_detection_status = {}
            for class_id, true_points in true_masks.items():
                is_detected = self._evaluate_single_class(
                    class_id,
                    detected_classes.get(class_id, []),
                    true_points,
                    results[0],
                    rotation_angle
                )
                class_detection_status[class_id] = is_detected

            # æ”¶é›†mAPæ•°æ®ï¼ˆå­¦æœ¯æŒ‡æ ‡ï¼Œä¸å—æ£€æµ‹æ¬¡æ•°é™åˆ¶ï¼‰
            self._collect_map_data(results[0], true_masks, rotation_angle)

            # åˆ¤æ–­æ•´ä½“æˆåŠŸï¼šæ‰€æœ‰æœ‰GTçš„ç±»åˆ«éƒ½æ°å¥½æ£€æµ‹ä¸€æ¬¡
            overall_success = all(class_detection_status.values())
            if overall_success:
                self.overall_success_count += 1

            # å¯è§†åŒ–
            self.visualize_sample(npy_file, dual_tensor, detected_classes, true_masks, results, rotation_angle, overall_success)

            return overall_success

        except Exception as e:
            print(f"å¤„ç†å¤±è´¥ {npy_file}: {e}")
            return False

    def _evaluate_single_class(self, class_id, detection_indices, true_points, result, rotation_angle):
        """
        è¯„ä¼°å•ä¸ªç±»åˆ«çš„æ£€æµ‹ç»“æœï¼ˆåŒ»å­¦ä¸¥æ ¼æ ‡å‡†ï¼‰
        è¿”å›: æ˜¯å¦æ­£ç¡®æ£€æµ‹ï¼ˆæ°å¥½æ£€æµ‹ä¸€æ¬¡ï¼‰
        """
        metrics = self.per_class_metrics[class_id]['medical_metrics']
        metrics['total_samples'] += 1

        # æ£€æŸ¥æ˜¯å¦æ°å¥½æ£€æµ‹ä¸€æ¬¡
        if len(detection_indices) != 1:
            return False

        # æå–é¢„æµ‹ç»“æœ
        detection_idx = detection_indices[0]
        pred_points = result[detection_idx].masks.xyn[0].copy()
        pred_points[:, 0] *= 1504
        pred_points[:, 1] *= 1504

        # è®¡ç®—IoU
        iou = self.calculate_iou(pred_points, true_points)

        # è®¡ç®—è¡¨é¢å·®å¼‚
        upper_diff, lower_diff = self.calculate_surface_diff(pred_points, true_points, rotation_angle)

        # è®°å½•æ•°æ®
        metrics['detected_samples'] += 1
        metrics['iou_scores'].append(iou)
        metrics['upper_surface_diffs'].append(upper_diff)
        metrics['lower_surface_diffs'].append(lower_diff)

        self.per_class_metrics[class_id]['raw_data']['iou_scores'].append(iou)
        self.per_class_metrics[class_id]['raw_data']['upper_surface_diffs'].append(upper_diff)
        self.per_class_metrics[class_id]['raw_data']['lower_surface_diffs'].append(lower_diff)

        return True

    def _collect_map_data(self, result, true_masks, rotation_angle):
        """æ”¶é›†mAPè®¡ç®—æ‰€éœ€æ•°æ®ï¼ˆåªè®¡ç®—Mask mAPï¼‰"""
        if not hasattr(result, 'boxes') or result.boxes is None or len(result.boxes) == 0:
            # æ— æ£€æµ‹ä½†æœ‰GTï¼Œéœ€è¦è®°å½•target_cls
            if true_masks:
                target_cls = np.array(list(true_masks.keys()))
                self.map_calculator.collect(
                    np.array([]).reshape(0, 10),  # ç©ºtp_mask
                    np.array([]),  # ç©ºconf
                    np.array([]),  # ç©ºpred_cls
                    target_cls
                )
            return

        n_pred = len(result.boxes)

        # æå–é¢„æµ‹ä¿¡æ¯
        pred_confs = result.boxes.conf.cpu().numpy()  # (n_pred,)
        pred_classes = result.boxes.cls.cpu().numpy().astype(int)  # (n_pred,)

        # æå–é¢„æµ‹masks
        pred_masks = []
        for i in range(n_pred):
            mask_points = result[i].masks.xyn[0].copy()
            mask_points[:, 0] *= 1504
            mask_points[:, 1] *= 1504
            pred_masks.append(mask_points)

        # æå–GTä¿¡æ¯
        gt_masks = []
        gt_classes = []
        for class_id, true_points in true_masks.items():
            gt_masks.append(true_points)
            gt_classes.append(class_id)

        gt_classes = np.array(gt_classes)  # (n_gt,)

        # è®¡ç®—TPçŸ©é˜µï¼ˆ10ä¸ªIoUé˜ˆå€¼ï¼Œåªè®¡ç®—Maskï¼‰
        iou_thresholds = np.linspace(0.5, 0.95, 10)
        tp_mask = np.zeros((n_pred, 10))

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        sorted_indices = np.argsort(-pred_confs)

        for threshold_idx, iou_threshold in enumerate(iou_thresholds):
            matched_gts = set()

            for pred_idx in sorted_indices:
                pred_class = pred_classes[pred_idx]

                # æ‰¾åˆ°åŒç±»åˆ«çš„GT
                best_iou_mask = 0
                best_gt_idx = -1

                for gt_idx in range(len(gt_classes)):
                    if gt_classes[gt_idx] != pred_class:
                        continue
                    if gt_idx in matched_gts:
                        continue

                    # è®¡ç®—Mask IoU
                    mask_iou = self.calculate_iou(pred_masks[pred_idx], gt_masks[gt_idx])

                    if mask_iou > best_iou_mask:
                        best_iou_mask = mask_iou
                        best_gt_idx = gt_idx

                # åˆ¤å®šTP
                if best_gt_idx >= 0 and best_iou_mask >= iou_threshold:
                    tp_mask[pred_idx, threshold_idx] = 1
                    if threshold_idx == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªé˜ˆå€¼æ—¶åŒ¹é…GT
                        matched_gts.add(best_gt_idx)

        # æ”¶é›†åˆ°mAPè®¡ç®—å™¨
        self.map_calculator.collect(tp_mask, pred_confs, pred_classes, gt_classes)

    def run_evaluation(self):
        """è¿è¡Œå®Œæ•´è¯„ä¼°"""
        if not self.load_model():
            return

        # æ•°æ®è·¯å¾„
        dataset_path = self.project_root / 'datasets' / 'Dual-Modal-1504-500-1-6ch'
        test_images = dataset_path / 'test' / 'images'
        test_labels = dataset_path / 'test' / 'labels'

        # è·å–æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        npy_files = sorted([f for f in os.listdir(test_images)
                           if f.endswith('.npy') and f.split('_')[-1].replace('.npy', '') in self.config.strategies])

        self.total_images = len(npy_files)
        print(f"å¼€å§‹è¯„ä¼° {self.total_images} å¼ å›¾åƒï¼Œç½®ä¿¡åº¦é˜ˆå€¼: {self.conf_threshold}")

        # é€ä¸ªè¯„ä¼°
        for npy_file in tqdm(npy_files, desc="è¯„ä¼°è¿›åº¦"):
            self.evaluate_single_image(npy_file, test_images, test_labels)

        # è®¡ç®—æœ€ç»ˆæ£€æµ‹ç‡
        for class_id in self.per_class_metrics:
            metrics = self.per_class_metrics[class_id]['medical_metrics']
            if metrics['total_samples'] > 0:
                metrics['detection_rate'] = metrics['detected_samples'] / metrics['total_samples']

        # ä¿å­˜ç»“æœ
        self.save_results()
        self.print_results()

    def save_results(self):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        # è®¡ç®—ç»Ÿè®¡é‡
        for class_id in self.per_class_metrics:
            metrics = self.per_class_metrics[class_id]['medical_metrics']
            if metrics['iou_scores']:
                metrics['iou_mean'] = float(np.mean(metrics['iou_scores']))
                metrics['iou_std'] = float(np.std(metrics['iou_scores']))
                metrics['upper_diff_mean'] = float(np.mean(metrics['upper_surface_diffs']))
                metrics['upper_diff_std'] = float(np.std(metrics['upper_surface_diffs']))
                metrics['lower_diff_mean'] = float(np.mean(metrics['lower_surface_diffs']))
                metrics['lower_diff_std'] = float(np.std(metrics['lower_surface_diffs']))

        # è®¡ç®—mAP
        map_results = self.map_calculator.compute()

        # æ„å»ºä¿å­˜æ•°æ®
        save_data = {
            'evaluation_metadata': {
                'model': self.fusion_name,
                'conf_threshold': float(self.conf_threshold),
                'total_images': int(self.total_images),
                'dataset': 'Dual-Modal-1504-500-1-6ch/test'
            },
            'per_class_metrics': {},
            'aggregate_metrics': {
                'medical': {
                    'overall_detection_rate': (
                        self.overall_success_count / self.total_images if self.total_images > 0 else 0.0
                    ),
                    'overall_detection_rate_description': 'æ‰€æœ‰ç±»åˆ«éƒ½æ­£ç¡®æ£€æµ‹çš„æ ·æœ¬æ¯”ä¾‹'
                },
                'academic': {}
            }
        }

        # ä¿å­˜æ¯ä¸ªç±»åˆ«çš„ç»“æœ
        for class_id, config in self.class_config.items():
            class_key = f"class_{class_id}_{config['name']}"

            metrics = self.per_class_metrics[class_id]
            class_data = {
                'class_id': int(class_id),
                'class_name': config['name'],
                'display_name': config['display_name'],
                'total_samples': int(metrics['medical_metrics']['total_samples']),
                'medical_metrics': {
                    k: (float(v) if isinstance(v, (int, float, np.number)) else v)
                    for k, v in metrics['medical_metrics'].items()
                    if k not in ['iou_scores', 'upper_surface_diffs', 'lower_surface_diffs']
                },
                'raw_data': {
                    k: [float(x) for x in v]
                    for k, v in metrics['raw_data'].items()
                }
            }

            # æ·»åŠ å­¦æœ¯æŒ‡æ ‡
            if map_results and class_id in map_results:
                class_data['academic_metrics'] = map_results[class_id]

            save_data['per_class_metrics'][class_key] = class_data

        # è®¡ç®—aggregate academic metricsï¼ˆåªä¿ç•™Mask mAPï¼‰
        if map_results:
            all_classes_ap = list(map_results.values())
            save_data['aggregate_metrics']['academic'] = {
                'mean_mask_ap50': float(np.mean([c['mask_ap50'] for c in all_classes_ap])),
                'mean_mask_ap50_95': float(np.mean([c['mask_ap50_95'] for c in all_classes_ap])),
                'mean_precision': float(np.mean([c['precision'] for c in all_classes_ap])),
                'mean_recall': float(np.mean([c['recall'] for c in all_classes_ap])),
                'mean_f1': float(np.mean([c['f1_score'] for c in all_classes_ap]))
            }

        # ä¿å­˜JSON
        metrics_file = self.results_dir / f'metrics_{self.fusion_name}.json'
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°: {metrics_file}")

    def print_results(self):
        """æ‰“å°è¯„ä¼°ç»“æœï¼ˆä¼˜åŒ–ç‰ˆï¼šMask mAPä¸ºä¸»ï¼ŒDetection Rateå¼±åŒ–ï¼‰"""
        print(f'\n{"="*70}')
        print(f'  {self.fusion_name} è¯„ä¼°ç»“æœ (ç½®ä¿¡åº¦: {self.conf_threshold})')
        print(f'{"="*70}')
        print(f'æ€»æµ‹è¯•å›¾åƒ: {self.total_images}\n')

        # æŒ‰ç±»åˆ«æ‰“å°
        for class_id, config in self.class_config.items():
            metrics = self.per_class_metrics[class_id]['medical_metrics']

            print(f'â”Œ{"â”€"*68}â”')
            print(f'â”‚ Class {class_id}: {config["name"]:<10} ({config["display_name"]})' + ' ' * (68 - 20 - len(config['name']) - len(config['display_name'])) + 'â”‚')
            print(f'â”œ{"â”€"*68}â”¤')

            # ä¸»è¦æŒ‡æ ‡ï¼šMask mAP
            map_results = self.map_calculator.compute()
            if map_results and class_id in map_results:
                ap = map_results[class_id]
                print(f'â”‚ ä¸»è¦æŒ‡æ ‡ (Mask mAP & Performance)' + ' ' * 35 + 'â”‚')
                print(f'â”‚   mAP@0.5: {ap["mask_ap50"]:.4f}  mAP@0.5:0.95: {ap["mask_ap50_95"]:.4f}' + ' ' * 24 + 'â”‚')
                print(f'â”‚   Precision: {ap["precision"]:.4f}  Recall: {ap["recall"]:.4f}  F1: {ap["f1_score"]:.4f}' + ' ' * 15 + 'â”‚')

            # è¾…åŠ©æŒ‡æ ‡ï¼šDetection Rate, IoU, Surface Diff
            print(f'â”‚' + ' ' * 68 + 'â”‚')
            print(f'â”‚ è¾…åŠ©æŒ‡æ ‡ (Medical Metrics - conf={self.conf_threshold})' + ' ' * 18 + 'â”‚')
            detected = metrics['detected_samples']
            total = metrics['total_samples']
            rate = metrics['detection_rate']
            print(f'â”‚   æ£€æµ‹ç‡: {rate:.2%} ({detected}/{total})' + ' ' * (68 - 23 - len(str(detected)) - len(str(total))) + 'â”‚')

            if metrics.get('iou_mean') is not None:
                print(f'â”‚   å¹³å‡IoU: {metrics["iou_mean"]:.4f} Â± {metrics["iou_std"]:.4f}' + ' ' * 33 + 'â”‚')
                print(f'â”‚   ä¸Šè¡¨é¢å·®å¼‚: {metrics["upper_diff_mean"]:.2f} Â± {metrics["upper_diff_std"]:.2f} åƒç´ ' + ' ' * 30 + 'â”‚')
                print(f'â”‚   ä¸‹è¡¨é¢å·®å¼‚: {metrics["lower_diff_mean"]:.2f} Â± {metrics["lower_diff_std"]:.2f} åƒç´ ' + ' ' * 30 + 'â”‚')

            print(f'â””{"â”€"*68}â”˜\n')

        # æ€»ä½“æŒ‡æ ‡
        print(f'â”Œ{"â”€"*68}â”')
        print(f'â”‚ æ€»ä½“æŒ‡æ ‡ (Overall Metrics - è·¨ç±»åˆ«å¹³å‡)' + ' ' * 30 + 'â”‚')
        print(f'â”œ{"â”€"*68}â”¤')

        map_results = self.map_calculator.compute()
        if map_results:
            all_classes_ap = list(map_results.values())
            print(f'â”‚ ä¸»è¦æŒ‡æ ‡ (Mask mAP)' + ' ' * 49 + 'â”‚')
            mean_mask_ap50 = np.mean([c['mask_ap50'] for c in all_classes_ap])
            mean_mask_ap50_95 = np.mean([c['mask_ap50_95'] for c in all_classes_ap])
            print(f'â”‚   mAP@0.5: {mean_mask_ap50:.4f}  mAP@0.5:0.95: {mean_mask_ap50_95:.4f}' + ' ' * 26 + 'â”‚')
            mean_prec = np.mean([c['precision'] for c in all_classes_ap])
            mean_rec = np.mean([c['recall'] for c in all_classes_ap])
            mean_f1 = np.mean([c['f1_score'] for c in all_classes_ap])
            print(f'â”‚   Precision: {mean_prec:.4f}  Recall: {mean_rec:.4f}  F1: {mean_f1:.4f}' + ' ' * 15 + 'â”‚')

        overall_rate = self.overall_success_count / self.total_images if self.total_images > 0 else 0.0
        print(f'â”‚' + ' ' * 68 + 'â”‚')
        print(f'â”‚ è¾…åŠ©æŒ‡æ ‡ (åŒ»å­¦ä¸¥æ ¼æ ‡å‡†)' + ' ' * 45 + 'â”‚')
        print(f'â”‚   æ‰€æœ‰ç±»åˆ«æ­£ç¡®æ£€æµ‹ç‡: {overall_rate:.2%} ({self.overall_success_count}/{self.total_images})' + ' ' * (68 - 34 - len(str(self.overall_success_count)) - len(str(self.total_images))) + 'â”‚')

        print(f'â””{"â”€"*68}â”˜')

        # æŒ‡æ ‡è¯´æ˜
        print('\nğŸ“Œ æŒ‡æ ‡è¯´æ˜:')
        print('  ä¸»è¦æŒ‡æ ‡:')
        print('    - Mask mAP@0.5:0.95: å­¦æœ¯æ ‡å‡†åˆ†å‰²ç²¾åº¦ (IoUä»0.5åˆ°0.95çš„å¹³å‡)')
        print('    - Recall: å¬å›ç‡ (é¿å…æ¼æ£€çš„å…³é”®æŒ‡æ ‡)')
        print('    - F1 Score: ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡')
        print('  è¾…åŠ©æŒ‡æ ‡:')
        print('    - æ£€æµ‹ç‡: åŒ»å­¦ä¸¥æ ¼æ ‡å‡† (æ°å¥½æ£€æµ‹1æ¬¡çš„æ ·æœ¬æ¯”ä¾‹)')
        print('    - å¹³å‡IoU: åˆ†å‰²è´¨é‡')
        print('    - è¡¨é¢å·®å¼‚: ä¸Šä¸‹è¾¹ç•Œå®šä½è¯¯å·® (åƒç´ )')


def main():
    """ä¸»å‡½æ•°"""
    fusion_names = ['crossattn-precise']
    # fusion_names = ['crossattn', 'crossattn-precise', 'weighted-fusion', 'concat-compress'] # 'id-white', 'id-blue', 
    conf_thresholds = [0.5, 0.6, 0.65, 0.7, 0.75]
    train_mode = 'scratch'  # 'scratch', 'pretrained', 'freeze_backbone'

    for fusion_name in fusion_names:
        for conf_threshold in conf_thresholds:
            print(f"\n{'='*70}")
            print(f"å¼€å§‹è¯„ä¼°: {fusion_name}, ç½®ä¿¡åº¦: {conf_threshold}")
            print(f"{'='*70}")
            evaluator = DualYOLOEvaluatorV3(fusion_name, train_mode, conf_threshold)
            evaluator.run_evaluation()


if __name__ == '__main__':
    main()